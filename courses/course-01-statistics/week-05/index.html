<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Week 5: Conditional Probability and Bayes' Theorem">
    <title>Week 5: Conditional Probability & Bayes' Theorem | SMU Applied AI</title>
    <link rel="stylesheet" href="../../../assets/styles.css">
</head>

<body>
    <nav class="navbar">
        <div class="navbar-content">
            <a href="../index.html" class="navbar-back">Course Home</a>
            <div class="navbar-subtitle">Week 5: Conditional Probability & Bayes' Theorem</div>
        </div>
    </nav>

    <main class="container">
        <div class="card">
            <span class="badge badge-foundation">Week 5 of 15</span>
            <h1>Conditional Probability & Bayes' Theorem</h1>
            <p>This week introduces Bayes' theorem, the foundation of Bayesian inference and a cornerstone of modern AI.
                Understanding how to update beliefs with evidence is essential for probabilistic reasoning.</p>

            <h2>Learning Objectives</h2>
            <ul class="objectives-list">
                <li>Apply conditional probability to update probabilities with new information</li>
                <li>Derive and apply Bayes' theorem in various contexts</li>
                <li>Distinguish between prior, likelihood, and posterior probabilities</li>
                <li>Use the law of total probability for partition-based calculations</li>
                <li>Apply Bayesian reasoning to real-world problems like medical diagnosis</li>
            </ul>

            <h2>Key Concepts</h2>
            <div class="resources-section">
                <ul>
                    <li><strong>Conditional Probability:</strong> P(A|B) = P(A ∩ B) / P(B)</li>
                    <li><strong>Bayes' Theorem:</strong> P(A|B) = P(B|A)P(A) / P(B)</li>
                    <li><strong>Prior:</strong> P(θ) - initial belief before seeing data</li>
                    <li><strong>Likelihood:</strong> P(D|θ) - probability of data given hypothesis</li>
                    <li><strong>Posterior:</strong> P(θ|D) - updated belief after seeing data</li>
                    <li><strong>Law of Total Probability:</strong> P(B) = Σ P(B|Aᵢ)P(Aᵢ)</li>
                </ul>
            </div>

            <h2>Week Resources</h2>
            <div class="btn-group">
                <a href="quiz.html" class="btn btn-primary">Take Quiz</a>
                <a href="discussion.html" class="btn btn-secondary">Discussion Topics</a>
            </div>
        </div>

        <div class="card mt-2">
            <h3>Week Navigation</h3>
            <div class="btn-group">
                <a href="../week-04/index.html" class="btn btn-secondary">← Week 4: Joint Distributions</a>
                <a href="../week-06/index.html" class="btn btn-primary">Week 6: Central Limit Theorem →</a>
            </div>
        </div>
    </main>

    <footer class="footer">
        <p>© 2026 SMU Lyle School of Engineering | Masters in Applied Artificial Intelligence</p>
        <p><a href="../../../index.html">Program Home</a> | <a href="../index.html">Course Home</a></p>
    </footer>
</body>

</html>